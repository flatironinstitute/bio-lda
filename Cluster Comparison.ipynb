{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865e91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from numba import jit\n",
    "from keras.datasets import mnist\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af64a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mnist = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ecd3f",
   "metadata": {},
   "source": [
    "# Gaussian Blob Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aeacbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_mnist:\n",
    "    x_dim = 2 # dimension of observations\n",
    "    num_clusters = 10\n",
    "    mus = []\n",
    "\n",
    "    sig = np.random.randn(x_dim,x_dim)/np.sqrt(x_dim)\n",
    "    Sigma = sig@sig.T\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        mus.append(10*np.random.randn(x_dim,1))\n",
    "\n",
    "    per_class_sample = 1000 # number of data points\n",
    "    samples = per_class_sample * num_clusters\n",
    "\n",
    "    classes = []\n",
    "    for i in range(num_clusters):\n",
    "        classes.append(mus[i] + np.random.randn(x_dim,int(per_class_sample)))\n",
    "\n",
    "    X = np.concatenate(classes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9e80f",
   "metadata": {},
   "source": [
    "# MNIST 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f4bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = False\n",
    "if use_mnist:\n",
    "    if full:\n",
    "        (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "        train_X = train_X.reshape(-1,784).astype(np.float64)\n",
    "        test_X = test_X.reshape(-1,784).astype(np.float64)\n",
    "    if not full:\n",
    "        digits = datasets.load_digits()\n",
    "        train_X, test_X, train_y, test_y = train_test_split(digits.data, digits.target, test_size=0.4, random_state=4)\n",
    "        train_X = train_X.reshape(-1,64).astype(np.float64)\n",
    "        test_X = test_X.reshape(-1,64).astype(np.float64)\n",
    "    samples = train_X.shape[0]\n",
    "    x_dim = train_X.shape[1]\n",
    "    X = train_X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0212fc5",
   "metadata": {},
   "source": [
    "# Hard Clustering (Neural + Non-Neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5960a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mnist:\n",
    "    num_clusters = 100\n",
    "else:\n",
    "    num_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "318f5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31047bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10000\n",
      "2\n",
      "False\n",
      "(2, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(num_clusters)\n",
    "print(samples)\n",
    "print(x_dim)\n",
    "print(neural)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0731301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:02<00:00, 3898.55it/s]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(num_clusters,x_dim)\n",
    "theta = np.random.randn(num_clusters,1)\n",
    "n = np.ones((num_clusters,1))\n",
    "Y = np.zeros((num_clusters,samples))\n",
    "eta = .1\n",
    "rho = 5\n",
    "\n",
    "\n",
    "\n",
    "#idx = np.random.permutation(samples)\n",
    "\n",
    "#s = np.empty(idx.size, dtype=np.int32)\n",
    "#for i in np.arange(idx.size):\n",
    "#    s[idx[i]] = i\n",
    "    \n",
    "    \n",
    "#X = X[:, idx]\n",
    "#Z = Z[:, idx]\n",
    "\n",
    "err = [[] for _ in range(samples)]\n",
    "    \n",
    "    \n",
    "W = 0.5 * np.random.randn(num_clusters,x_dim)\n",
    "theta = np.random.randn(num_clusters,1)\n",
    "n = np.ones((num_clusters,1))\n",
    "Y = np.zeros((num_clusters,samples)) \n",
    "\n",
    "\n",
    "for t in tqdm(range(samples)):\n",
    "    x = X[:,t].reshape((x_dim,1))\n",
    "    a = -W@x + theta\n",
    "    y = np.zeros((num_clusters,1))\n",
    "    z = np.zeros(1)\n",
    "\n",
    "    if neural: ## Neural Step 3\n",
    "\n",
    "        er  = 1\n",
    "        itr = 1\n",
    "\n",
    "        # Iterate until convergence\n",
    "        while er > 1e-7:\n",
    "\n",
    "            z_prev = z\n",
    "            y_prev = y\n",
    "\n",
    "\n",
    "            # Update y and z\n",
    "            y = tf.nn.relu(y + (eta)*( -a - z - rho*(np.sum(y, axis=0) - 1) )).numpy()\n",
    "            z += eta*( np.sum(y, axis=0) - 1 )\n",
    "\n",
    "\n",
    "            er = max(np.linalg.norm(z_prev-z)/(np.linalg.norm(z_prev)+1e-4),\n",
    "                     np.linalg.norm(y_prev-y)/(np.linalg.norm(y_prev)+1e-4))\n",
    "            err[t].append(er)\n",
    "            itr += 1\n",
    "\n",
    "\n",
    "    else: ## Non=Neural Step 3\n",
    "        c = np.argmin(a)\n",
    "        y[c] = 1\n",
    "        z = -a[c]\n",
    "\n",
    "\n",
    "    #z = z[0]\n",
    "\n",
    "    #Step 4\n",
    "\n",
    "    n += y\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        for j in range(x_dim):\n",
    "            W[i,j] += y[i]*(2*x[j] - W[i,j])/min(n[i], 100)\n",
    "\n",
    "        theta[i] += y[i]*(z - theta[i])/min(n[i], 100)\n",
    "\n",
    "    for j in range(num_clusters):\n",
    "        Y[j,t] = y[j]\n",
    "\n",
    "#print(f'Cluster {1} mean: {W[0,:]/2}')\n",
    "#for i in range(num_clusters):\n",
    "#    print(f'Cluster {i+1} mean: {W[i,:]/2}')\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70a38101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63752870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73be308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8428"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(Y, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32567bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
